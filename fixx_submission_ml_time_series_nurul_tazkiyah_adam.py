# -*- coding: utf-8 -*-
"""Fixx Submission ML Time Series - Nurul Tazkiyah Adam.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16viupyT1eGY7zyIqoxk-rfX2v0ewmlbF

## **Prediksi Time Series Oleh Nurul Tazkiyah Adam**
"""

# memastikan tensorflow yang digunakan versi 2 atau lebih
import tensorflow as tf
print(tf.__version__)

# download dataset dari google drive https://drive.google.com/file/d/1ShO035_gg0piR9xrWq8utZh1lei4tBsA/view?usp=sharing
!gdown 1ShO035_gg0piR9xrWq8utZh1lei4tBsA

import pandas as pd

df = pd.read_csv('london_weather.csv')
df.head()

df.info()

df.isnull().sum()

df = df.drop(columns=['cloud_cover', 'sunshine', 'global_radiation','max_temp','min_temp', 'precipitation', 'pressure', 'snow_depth'])
df.shape

df.head()

import matplotlib.pyplot as plt

dates = df['date'].values
temp  = df['mean_temp'].values
 
plt.figure(figsize=(15,5))
plt.plot(df['date'].values, df['mean_temp'].values)
plt.title('temperature', fontsize=18)

"""# Impute Missing Value"""

import datetime
from datetime import date

df.columns=['date','mean_temp']

#  fromat date dalam bentuk Year, month dan day
df['date']=pd.to_datetime(df['date'], format='%Y-%m-%d')

# set date menjadi index
dataset= df.set_index('date')

# cek data shape
dataset.shape

dataset.head() # cek isi data setelah implementasi perubahan index dan format date

# membuat series True or False untuk data NaN (missing) and present data respectively. 
nul_data = pd.isnull(dataset['mean_temp']) 
    
# print only the data, mean_temp = NaN 
dataset[nul_data].head()

plt.rcParams['figure.figsize']=(15,7)

# untuk mengisi data yang hilang menggunakan mean dari data
dataset = dataset.assign(FillMeanTemp=dataset.mean_temp.fillna(dataset.mean_temp.mean()))

plt.plot(dataset, color='blue')

plt.title('Mean Temp Imputation')

plt.show()

dataset.head() #mengecek data setelah memperbaiki missing value

dataset.shape

dataset.reset_index(drop=False, inplace=True) #mengembalikan index date ke data semula

dataset.info()

dataset.isnull().sum()

"""# Normalisasi"""

from sklearn import preprocessing
import numpy as np


scaler = preprocessing.MinMaxScaler()
tmp_scaler = scaler.fit_transform(dataset['FillMeanTemp'].values.reshape(-1,1))
tmp_scaler

tmp_fix = tmp_scaler.reshape(-1)

"""# Split Data"""

from sklearn.model_selection import train_test_split

#melatih data latih dan data uji 
dt_train, dt_test, tmp_train, tmp_test = train_test_split(dataset['date'].values, tmp_fix, test_size=0.2, shuffle=False)
print(dt_train.shape, tmp_train.shape)
print(dt_test.shape, tmp_test.shape)

#mengubah data kita menjadi format yang dapat diterima oleh model. 
#series/atribut dikonversi menjadi tipe numpy, lalu mengembalikan label dan atribut dari dataset dalam bentuk batch.

def windowed_dataset(series, window_size, batch_size, shuffle_buffer):
    series = tf.expand_dims(series, axis=-1)
    ds = tf.data.Dataset.from_tensor_slices(series)
    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)
    ds = ds.flat_map(lambda w: w.batch(window_size + 1))
    ds = ds.shuffle(shuffle_buffer)
    ds = ds.map(lambda w: (w[:-1], w[-1:]))
    return ds.batch(batch_size).prefetch(1)

train_set = windowed_dataset(tmp_train, window_size=60, batch_size=100, shuffle_buffer=1000)
val_set = windowed_dataset(tmp_test, window_size=60, batch_size=100, shuffle_buffer=1000)

"""# Model """

from keras.models import Sequential
from keras.layers import Bidirectional, Dense, LSTM, Dropout

model = tf.keras.models.Sequential([
  tf.keras.layers.LSTM(60, return_sequences=True),
  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(60)),
  tf.keras.layers.Dense(30, activation="relu"),
  tf.keras.layers.Dropout(0.3),
  tf.keras.layers.Dense(10, activation="relu"),
  tf.keras.layers.Dense(1),
])

optimizer = tf.keras.optimizers.SGD(lr=1.0000e-04, momentum=0.9)
model.compile(loss=tf.keras.losses.Huber(),
                optimizer=optimizer,
                metrics=['mae'])

max_mae = (tmp_fix.max() - tmp_fix.min()) * 10/100
print(f'Batas nilai mae: harus dibawah {max_mae}')

class berhenti(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if (logs.get('mae') < 0.1):
      self.model.stop_training = True
      print('\nalhamdulillah MAE pada model telah < 10% skala data')
iniCallback = berhenti()

tf.keras.backend.set_floatx('float64')

history = model.fit(train_set,
                    validation_data = val_set, # menampilkan akurasi pengujian data validasi
                    epochs=500, batch_size=60, 
                    callbacks = [iniCallback])

import numpy as np

maee = history.history['mae']
val_mae = history.history['val_mae']

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(len(maee))

plt.figure(figsize=(20, 8))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, maee, label='Training MAE')
plt.plot(epochs_range, val_mae, label='Validation MAE')
plt.legend(loc='lower right')
plt.title('Training and Validation MAE')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')

"""# Prediksi"""

def model_forecast(model, series, window_size):
    ds = tf.data.Dataset.from_tensor_slices(series)
    ds = ds.window(window_size, shift=1, drop_remainder=True)
    ds = ds.flat_map(lambda w: w.batch(window_size))
    ds = ds.batch(32).prefetch(1)
    forecast = model.predict(ds)
    return forecast

# test prediksi 

test_dt = dataset['date'].values
test_tmp  = dataset['FillMeanTemp'].values

predictions = model_forecast(model, test_tmp, 60)
predictions = np.array([prediction[0] for prediction in predictions])
range = test_dt[:len(predictions)]

plt.figure(figsize=(20,5))
plt.plot(range, predictions)
plt.title('Temperature Predictions', fontsize=20)

"""## **Referensi**

1.   [Sukma Ramadhan, Time Series Prediksi Energy Usage](https://github.com/onedayxzn/Time-Series-Prediksi-Energy-Usage/blob/master/TimeSeriesPrediksiEnergyUsage.ipynb )
2.   [ Farhan, Membuat Model Machine Learning dengan Data Time Series](https://)
3.   [A Complete Guide on How to Impute Missing Values in Time Series in Python](hhttps://www.section.io/engineering-education/missing-values-in-time-series/)
4.  [ Time-Series Traffic Forecasting in Colab](https://youtu.be/xt8G0ltVl4Q)
5.  [Memprediksi Harga Emas dengan Backpropagation di Python (Dataset Kaggle)](https://youtu.be/Chg_Vtm-r88)

"""